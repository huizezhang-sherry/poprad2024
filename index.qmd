---
title: "Studying the Performance of the Jellyfish Search Optimiser for the Application of Projection Pursuit"
date: 2024-09-04
date-format: iso
author: 
 - name: "H. Sherry Zhang"
institute: "University of Texas at Austin"
css: style.css
format: 
  revealjs:
    scrollable: true
    slide-number: true
    show-slide-number: all
    aspectratio: 169
    theme: serif
    preview-links: auto
    footer: "https://sherryzhang-poprad2024.netlify.app"
execute:
  echo: true
self-contained: true
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE,
                      fig.align = 'center')
library(tidyverse)
library(ferrn)
library(tourr)
library(patchwork)
load(here::here("data/sim_df.rda"))
```
# Table of content

- Background: Projection pursuit (PP) and optimisation
- The Jellyfish Search Optimiser (JSO)
- Two new metrics, smoothness and squintability, to characterise PP optimisation
- Simulation study

# [Optimisation in projection pursuit]{.r-fit-text} {.smaller}

::: columns
::: column
-   Data: $\mathbf{X}_{n \times p}$; Basis: $\mathbf{A}_{p\times d}$
-   Projection: $\mathbf{Y} = \mathbf{X} \cdot \mathbf{A}$
-   Index function: $f: \mathbb{R}^{n \times d} \mapsto \mathbb{R}$
-   Optimisation: $\arg \max_{\mathbf{A}} f(\mathbf{X} \cdot \mathbf{A}) ~~~ s.t. ~~~ \mathbf{A}^{\prime} \mathbf{A} = I_d$
:::

::: column
<!-- -   5 vars ($x_1$ - $x_5$), 1000 obs simulated -->
<!--     -   One variable ($x_2$) is a mixture normal -->
<!--     -   others are random normal -->
<!-- -   1D projection using the holes index: $\propto 1 -\frac{1}{n} \sum_{i = 1}^n \exp(-\frac{1}{2} y_i y_i^{\prime})$ -->
:::
:::

```{r fig.height=2.5, eval = FALSE}
# set.seed(123456)
# a <- animate_dist(
#   boa5, tour_path = guided_tour(holes(), d = 1, search_f = search_geodesic)) 
# first_dir <- a$basis[[1]]
# last_dir <- tail(a$basis, 1)[[1]]
first_dir <- matrix(c(0.34, -0.11, -0.14, 0.03, 0.92))
last_dir <- matrix(c(0.01, -0.99, -0.01, 0.04, 0.007))
p1 <- as.matrix(boa5) %*% first_dir |> 
  as_tibble() |> 
  ggplot() + 
  geom_density(aes(x = V1), fill = "black") + 
  theme_void() + 
  theme(aspect.ratio = 1) + 
  labs(x = "Projection", title = "start", y = "") + 
  theme(panel.border = element_rect(fill = "transparent"))

p2 <- as.matrix(boa5) %*% last_dir |> 
  as_tibble() |> 
  ggplot() + 
  geom_density(aes(x = V1), fill = "black") + 
  theme_void() + 
  theme(aspect.ratio = 1) + 
  labs(x = "Projection", title = "finish", y = "") + 
  theme(panel.border = element_rect(fill = "transparent"))

p1 | p2
```

::: notes
```         
- Projection basis which gives a d-dimensional projection; characterise, the direction from which the data get projected; 
- Index function: maps the projection to a scalar, 
- measures interestingness, theoretical results show that, depart from normal distribution, intuitive explanation, CLT, more observations,  data distributed as normal
- Optimisation: max the index, subject to orthonormality constraint
```
:::

# [Projection pursuit with guided tour]{.r-fit-text} {.smaller}

::: columns
::: column
```{r echo = FALSE, fig.align="center", out.width="100%"}
knitr::include_graphics("figures/tour-path.png")
```
:::

::: column
-   projection pursuit: maximises the index function to iteratively find better basis/ projection ([**blue frames**]{style="color:#2E6BA9"})
-   guided tour: chains these projections together through interpolation (**white frames**) and produces an smooth animation

TODO: tourr package logo
:::
:::

## From past research ... {.smaller}

> The work also reveals inadequacies in the tour optimization algorithm, that may benefit from newly developed techniques and software tools. Exploring this area would help improve the guided tours. As new optimization techniques become available, adapting these to the guided tour would extend the technique to a broader range of problems. (Laa & Cook, 2020)

::: {layout-ncol=4}

![](figures/pca-plot.png){width=50%} 

![](figures/pca.gif){width=50%} 

![](figures/tour.gif){width=50%} 

![](figures/tour-frame078.png){width=50%} 
:::

# Now, let's investigate a new optimiser

## The Jellyfish search optimiser {.smaller}

*Chou, J. S., & Truong, D. N. (2021). A novel metaheuristic optimizer inspired by behavior of jellyfish in ocean. Applied Mathematics and Computation, Volume 389, 125535.*

![](figures/JSO-paper.png)

## A diagram to explain the Jellyfish search optimiser {.smaller}

TODO

## A snapshot of the optimiser in the R code 

TODO

maybe need to explain the tourr code?? - please don't users don't need to know that much...

## An animation of JSO in action

TODO

# [Properties of the index function <br> for characterising the optimisation task]{.r-fit-text}

## [Properties proposed: smoothness, squintability, and speed]{.r-fit-text}

![](figures/PPI-property-paper.png)


*The paper also mentions flexibility and rotation invariance but they are less relevant for the optimisation*

## Smoothness 

what does it mean by smooth and not smooth

![](figures/smoothness.png)

## Squintability

A small squint angle because you have to be very close to the optimal
projection plane to be able to see the structure of the data.

(we see a hill over there! Now we see a hill)

## Define Squintability {.smaller}

::::columns

:::{.column width=50%}
**Projection distance** between two bases $A$ and $A^*$, $d(A, A^*)$:

$$d(A, A^*) = \lVert AA^\prime - A^*A^{*\prime}\  \rVert _F$$

where $\lVert . \rVert _F$ denotes the Frobenius norm, given by
$\lVert M \rVert _F = \sqrt{\sum_{ij} M_{ij}^2}$. 

<br> 

**Index-distance curve** $g$ maps $d(A, A^*)$ to the index value $f(XA)$, such that $$g(d(A, A^*)) = f(XA)$$
:::

:::{.column width=50%}

```{r}
dt <- tibble(x = seq(0, 2, 0.02), 
       y = 1/ (1 + exp(3.5 * (x - 1.1)))) |> 
  mutate(dy = abs(y - lag(y)))

dt |>
  ggplot(aes(x = x, y = y)) + 
  geom_line() + 
  geom_point(data = dt |> filter(x == 1.1), color = "red", size = 3) + 
  geom_abline(intercept = 0.0175 / 0.02 * 1.1 + 0.5, slope = -0.0175/0.02, 
              linetype = "dashed") + 
  geom_segment(aes(x = 1.1, y = 0.5, yend = -Inf), linetype = "dashed") + 
  geom_label(aes(x = 1, y = 0.9, label = "max gradient on \n the curve: -0.4625")) + 
  geom_label(aes(x = 1.25, y = 0, label = "d = 1.1")) + 
  
  theme_bw() + 
  labs(x = "Projection distance", y = "Index value") 


```

**Squintability**: 

$$\varsigma(f) = -c \times \max_{d} g'(d) \times \arg \max_{d} g'(d)$$

use c = 4 to be consistent with estimating with parametric model

:::

::::


## Calculate squintability {.smaller}

![](figures/squintability.png)

**sigmoid curve**: $\ell(x):=\frac{1}{1+\exp(\theta_{3}(x-\theta_{2}))}\ $ 

**parametric model**: $f(x)=(\theta_{1}-\theta_{4})\frac{\ell(x)-\ell(x_{\max})}{\ell(0)-\ell(x_{\max})}+\theta_{4}\ $

**Squintability: ** $\varsigma=\frac{(\theta_{1}-\theta_{4})\theta_{2}\theta_{3}}{\ell(0)-\ell(x_{\max})}$ 


## Example: 

shall I do a specific calculation example here? 

# [Simulation: Link JSO optimisers <br> with smoothness, squintability <br> and others]{.r-fit-text}

## Simulation setup {.smaller}

```{r}
dt <- tibble(
  shape = c(rep("pipe", 4), rep("sine", 8)),
  index = c(rep("holes", 4), "MIC", "MIC", "TIC", "TIC", "dcor2d", "loess2d", "splines2d", "stringy"),
  d = c(6, 8, 10, 12, 6, 8, 6, 8, 6, 6, 6, 6)
)
```

:::columns

:::column

**the "pipe" shape**:

the holes index 

data dimension d = 6, 8, 10, 12

```{r}
p1 <- ferrn::pipe1000 |> as_tibble() |> ggplot(aes(x = V1, y = V3)) + geom_point() + labs(x = "", y = "")
p2 <- ferrn::pipe1000 |> as_tibble() |> ggplot(aes(x = V5, y = V6)) + geom_point() + labs(x = "", y = "")
p1 | p2
```

* different JSO hyper-parameters: 

    * number of jellyfishes (20, 50, 100)
    * maximum number of tries (50, 100)

:::

:::column

**the "sine" shape**:

index function:  *"MIC", "TIC", "dcor2d", "loess2d", "splines2d", "stringy"*

data dimension d = 6

```{r}
p1 <- ferrn::sine1000 |> as_tibble() |> ggplot(aes(x = V1, y = V2)) + geom_point() + labs(x = "", y = "")
p2 <- ferrn::sine1000 |> as_tibble() |> ggplot(aes(x = V5, y = V6)) + geom_point() + labs(x = "", y = "")
p1 | p2
```

For "MIC" and "TIC", d = 8 is also included

:::


:::

## Sucess rate {.smaller}


50 repetitions for each case to calculate success rate

xxx out of 50 that finds a final index value within 0.05 of the best index value found among all 50 simulations 

![](figures/success-rate.png)

## The generalised linear model  {.smaller}

*a binomial family and a logit link function*

<center>success rate ~ smoothness + squintability + n_jellies + max_tries + d + long_time</center>

data pre-processing: 

1) divide `n_jellies` and `max_tries` by 10 for interpretation, 
2) new binary variable `long_time` for average run time over 30 seconds

```{r}
sim_df |> 
  dplyr::select(index, d, smoothness, 
    squintability, n_jellies, max_tries, 
    -I_max, P_J, time) |> 
  mutate(time = as.numeric(time)) |>
  arrange(index, d, n_jellies, max_tries) |> 
  head(5) |> 
  knitr::kable(digits = 2,  
        col.names = c("index", "d", 
          "smoothness", "squintability", 
          "n. jellyfish", 
          "max. tries", 
          "success rate", "time (sec)"),
        linesep = "",
        booktabs = T)
```


## Results {.smaller}

```{r}
sim_df2 <- sim_df |>   
  mutate(n_jellies = n_jellies/10,
         max_tries = max_tries/10,
         long_time = ifelse(time > 20, 1, 0),
         P_J = ifelse(index == "stringy", 0, P_J))

mod1 <- glm(P_J ~ smoothness + squintability + d + long_time + n_jellies + max_tries, data = sim_df2, family = binomial)
broom::tidy(mod1) |> 
  mutate(term = c("Intercept", "Smoothness",
   "Squintability", "Dimension (d)", 
   "Long time", "N. jellyfish", 
   "Max. tries")) |>
  knitr::kable(digits = 2, format = "html", linesep = "", booktabs = T) |> 
  kableExtra::row_spec(1:7, extra_css = "border-bottom-style: none")

```


* The signs of the variables are as expected 
* The variable squintability and dimension are significant - sugguesting their influence the success of the optimisation

## Takeaway {.smaller}

* The JSO is implemented in the `tourr` package.

* The two metrics, smoothness and squintability, are proposed and implemented in the `ferrn` package. They can be used to characterise the diﬀiculty of the optimisation task and inform the choice of optimiser.

* Large squintability indicates a distinct difference in index values between optimal regions and others. When one jellyfish enters the optimal region, the high index value it generates will be clearly distinguishable from spurious values and lead other jellyfish to move toward the optimal region. 


### But also notice ... {.smaller}

* The two metrics are relative - comparison should be made with same parameters.

* Index values should be standardised to the [0, 1] interval

* Computational cost associated with population-based optimiser, i.e. JSO

## `r emo::ji("link")` {.smaller}

```{r echo = FALSE, eval = FALSE}
library(qrcode)
a <- qr_code("https://sherryzhang-porad2024.netlify.app/")
generate_svg(a, filename = "figures/qrcode.svg")
```

-   this slide:
    -   {{< fa link >}}: <https://sherryzhang-poprad2024.netlify.app>
    -   {{< fa brands github >}}: <https://github.com/huizezhang-sherry/poprad2024>
-   the `ferrn` package:
    -   {{< fa brands github >}}: <https://huizezhang-sherry.github.io/ferrn/>
    -   CRAN: <https://cran.r-project.org/web/packages/ferrn/index.html>
- the `tourr` package:
    -   {{< fa brands github >}}: <https://github.com/ggobi/tourr>
    -  CRAN: <https://cran.r-project.org/web/packages/tourr/index.html>
-   paper:
    - arxiv pre-print